{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('u_embeddings.weight',\n",
       "              tensor([[-0.0004, -0.0041,  0.0032,  ..., -0.0041,  0.0003,  0.0006],\n",
       "                      [ 0.0043,  0.0017,  0.0047,  ...,  0.0018, -0.0041,  0.0033],\n",
       "                      [-0.0021,  0.0017, -0.0031,  ...,  0.0048, -0.0042, -0.0044],\n",
       "                      ...,\n",
       "                      [ 0.0016, -0.0039,  0.0009,  ..., -0.0004,  0.0020,  0.0046],\n",
       "                      [ 0.0036,  0.0047, -0.0005,  ...,  0.0010, -0.0016, -0.0022],\n",
       "                      [ 0.0003, -0.0004, -0.0030,  ..., -0.0032,  0.0032,  0.0031]])),\n",
       "             ('v_embeddings.weight',\n",
       "              tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      ...,\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.]]))])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "init = torch.load('initial_state_dict_sgns.pth')\n",
    "init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('u_embeddings.weight',\n",
       "              tensor([[ 0.0012, -0.1110, -0.0614,  ..., -0.0707,  0.0100,  0.0796],\n",
       "                      [ 0.0316, -0.0280, -0.0487,  ..., -0.0661, -0.0004, -0.0005],\n",
       "                      [ 0.0323, -0.0611,  0.0128,  ...,  0.0134, -0.0244,  0.0239],\n",
       "                      ...,\n",
       "                      [ 0.0280, -0.0300, -0.0254,  ..., -0.0263,  0.0276,  0.0305],\n",
       "                      [ 0.0230, -0.0147, -0.0199,  ..., -0.0184,  0.0178,  0.0172],\n",
       "                      [ 0.0181, -0.0180, -0.0208,  ..., -0.0206,  0.0207,  0.0207]],\n",
       "                     device='cuda:0')),\n",
       "             ('v_embeddings.weight',\n",
       "              tensor([[-0.3988,  0.1705,  0.2404,  ...,  0.1758, -0.3485, -0.2241],\n",
       "                      [-0.1896,  0.1612,  0.1672,  ...,  0.1032, -0.2210, -0.2103],\n",
       "                      [-0.0178,  0.0582,  0.2122,  ...,  0.0733, -0.1144, -0.1156],\n",
       "                      ...,\n",
       "                      [-0.8320,  0.8458,  0.8173,  ...,  0.7397, -0.7814, -0.8113],\n",
       "                      [-0.8533,  0.8619,  0.8167,  ...,  0.7722, -0.7554, -0.8360],\n",
       "                      [-0.7837,  0.8141,  0.8239,  ...,  0.7547, -0.7019, -0.8132]],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = torch.load('final_state_dict_sgns.pth')\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data .................\n",
      "Total tokens: 17005207\n",
      "Vocabulary size: 71290\n"
     ]
    }
   ],
   "source": [
    "import data\n",
    "import model\n",
    "\n",
    "argsdata='data/text8'\n",
    "argsemsize = 200\n",
    "argsbatch_size = 1024\n",
    "argswindow_size=5\n",
    "argsneg_num=5\n",
    "argsmin_count=5\n",
    "\n",
    "\n",
    "\n",
    "my_data = data.DataReader(argsdata, argsmin_count)\n",
    "dataset = data.Word2vecDataset(my_data, argswindow_size, argsneg_num)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "  dataset, batch_size=argsbatch_size, collate_fn=dataset.collate)\n",
    "\n",
    "\n",
    "vocab_size = len(my_data.word2id)\n",
    "skip_gram_model = model.SkipGramModel(vocab_size, argsemsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-3.6993e-03,  4.6288e-03,  3.7557e-03,  ...,  7.1177e-04,\n",
       "          3.6588e-03, -4.0318e-03],\n",
       "        [-1.0194e-03,  3.7398e-03,  4.6692e-03,  ...,  3.0796e-03,\n",
       "         -3.4136e-03,  1.9667e-03],\n",
       "        [-9.1851e-05,  2.4013e-03,  3.5773e-03,  ...,  3.5610e-03,\n",
       "          9.6489e-04,  4.4999e-03],\n",
       "        ...,\n",
       "        [-3.2996e-03,  4.7290e-04,  9.6912e-05,  ..., -2.6575e-03,\n",
       "          4.2293e-03, -2.3318e-03],\n",
       "        [ 2.3152e-03,  2.4225e-03, -3.3027e-03,  ..., -4.4353e-03,\n",
       "         -3.6827e-03, -4.2459e-03],\n",
       "        [-2.4426e-03, -4.8704e-03, -3.7881e-03,  ..., -3.5959e-03,\n",
       "          1.2902e-03, -3.8541e-04]], requires_grad=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_gram_model.u_embeddings.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_gram_model.load_state_dict(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.3988,  0.1705,  0.2404,  ...,  0.1758, -0.3485, -0.2241],\n",
       "        [-0.1896,  0.1612,  0.1672,  ...,  0.1032, -0.2210, -0.2103],\n",
       "        [-0.0178,  0.0582,  0.2122,  ...,  0.0733, -0.1144, -0.1156],\n",
       "        ...,\n",
       "        [-0.8320,  0.8458,  0.8173,  ...,  0.7397, -0.7814, -0.8113],\n",
       "        [-0.8533,  0.8619,  0.8167,  ...,  0.7722, -0.7554, -0.8360],\n",
       "        [-0.7837,  0.8141,  0.8239,  ...,  0.7547, -0.7019, -0.8132]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_gram_model.v_embeddings.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(71290, 200)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune.l1_unstructured(skip_gram_model.v_embeddings, name='weight', amount=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight_orig', Parameter containing:\n",
      "tensor([[-0.3988,  0.1705,  0.2404,  ...,  0.1758, -0.3485, -0.2241],\n",
      "        [-0.1896,  0.1612,  0.1672,  ...,  0.1032, -0.2210, -0.2103],\n",
      "        [-0.0178,  0.0582,  0.2122,  ...,  0.0733, -0.1144, -0.1156],\n",
      "        ...,\n",
      "        [-0.8320,  0.8458,  0.8173,  ...,  0.7397, -0.7814, -0.8113],\n",
      "        [-0.8533,  0.8619,  0.8167,  ...,  0.7722, -0.7554, -0.8360],\n",
      "        [-0.7837,  0.8141,  0.8239,  ...,  0.7547, -0.7019, -0.8132]],\n",
      "       requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "print(list(skip_gram_model.v_embeddings.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight_mask', tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]]))]\n"
     ]
    }
   ],
   "source": [
    "print(list(skip_gram_model.v_embeddings.named_buffers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
      "        [-0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
      "        [-0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
      "        ...,\n",
      "        [-0.8320,  0.8458,  0.8173,  ...,  0.7397, -0.7814, -0.8113],\n",
      "        [-0.8533,  0.8619,  0.8167,  ...,  0.7722, -0.7554, -0.8360],\n",
      "        [-0.7837,  0.8141,  0.8239,  ...,  0.7547, -0.7019, -0.8132]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(skip_gram_model.v_embeddings.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([(0, <torch.nn.utils.prune.L1Unstructured object at 0x7f04f200ead0>)])\n"
     ]
    }
   ],
   "source": [
    "print(skip_gram_model.v_embeddings._forward_pre_hooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = skip_gram_model.v_embeddings.weight_mask\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=mask.bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight', Parameter containing:\n",
      "tensor([[-0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
      "        [-0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
      "        [-0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
      "        ...,\n",
      "        [-0.8320,  0.8458,  0.8173,  ...,  0.7397, -0.7814, -0.8113],\n",
      "        [-0.8533,  0.8619,  0.8167,  ...,  0.7722, -0.7554, -0.8360],\n",
      "        [-0.7837,  0.8141,  0.8239,  ...,  0.7547, -0.7019, -0.8132]],\n",
      "       requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "prune.remove(skip_gram_model.v_embeddings, 'weight')\n",
    "print(list(skip_gram_model.v_embeddings.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_gram_model.load_state_dict(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_size = dataset.data_len // argsbatch_size\n",
    "optimizer = torch.optim.Adam(skip_gram_model.parameters())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SkipGramModel(\n",
       "  (u_embeddings): Embedding(71290, 200)\n",
       "  (v_embeddings): Embedding(71290, 200)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_gram_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('u_embeddings.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0004, -0.0041,  0.0032,  ..., -0.0041,  0.0003,  0.0006],\n",
       "          [ 0.0043,  0.0017,  0.0047,  ...,  0.0018, -0.0041,  0.0033],\n",
       "          [-0.0021,  0.0017, -0.0031,  ...,  0.0048, -0.0042, -0.0044],\n",
       "          ...,\n",
       "          [ 0.0016, -0.0039,  0.0009,  ..., -0.0004,  0.0020,  0.0046],\n",
       "          [ 0.0036,  0.0047, -0.0005,  ...,  0.0010, -0.0016, -0.0022],\n",
       "          [ 0.0003, -0.0004, -0.0030,  ..., -0.0032,  0.0032,  0.0031]],\n",
       "         device='cuda:0', requires_grad=True)),\n",
       " ('v_embeddings.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', requires_grad=True))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(skip_gram_model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00 loss = 4.159, wps = 13662\n",
      "0.10 loss = 3.847, wps = 18821\n",
      "0.20 loss = 3.604, wps = 18800\n",
      "0.30 loss = 3.460, wps = 18942\n",
      "0.40 loss = 3.369, wps = 18854\n",
      "0.50 loss = 3.304, wps = 18953\n",
      "0.60 loss = 3.257, wps = 18880\n",
      "0.70 loss = 3.220, wps = 18922\n",
      "0.80 loss = 3.190, wps = 18838\n",
      "0.90 loss = 3.173, wps = 18766\n",
      "Epoch: 1, Loss = 3.156, "
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "\n",
    "for epoch in range(1):\n",
    "  last_time = time.time()\n",
    "  last_words = 0\n",
    "\n",
    "  total_loss = 0.0\n",
    "  \n",
    "  for step, batch in enumerate(dataloader):\n",
    "    pos_u = batch[0].to(\"cuda\")\n",
    "    pos_v = batch[1].to(\"cuda\")\n",
    "    neg_v = batch[2].to(\"cuda\")\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = skip_gram_model.forward(pos_u, pos_v, neg_v)\n",
    "    loss.backward()\n",
    "    \n",
    "    for name, p in skip_gram_model.named_parameters():\n",
    "        if 'v_embeddings' in name:\n",
    "            # p.grad.data=torch.where(torch.abs(p.data) < EPS, torch.tensor([0.]).cuda(), p.grad.data)\n",
    "            p.grad.data[~mask]=0\n",
    "              \n",
    "    optimizer.step()\n",
    "\n",
    "    total_loss += loss.item()\n",
    "\n",
    "    if step % (epoch_size // 10) == 10:\n",
    "      print('%.2f' % (step * 1.0 / epoch_size), end=' ')\n",
    "      print('loss = %.3f' % (total_loss / (step + 1)), end=', ')\n",
    "      now_time = time.time()\n",
    "      now_words = step * argsbatch_size\n",
    "      wps = (now_words - last_words) / (now_time - last_time)\n",
    "      print('wps = ' + str(int(wps)))\n",
    "      last_time = now_time\n",
    "      last_words = now_words\n",
    "\n",
    "  print(\"Epoch: \" + str(epoch + 1), end=\", \")\n",
    "  print(\"Loss = %.3f\" % (total_loss / epoch_size), end=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('u_embeddings.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.2349, -0.2946, -0.2017,  ..., -0.2508,  0.1768,  0.2420],\n",
       "          [-0.2470, -0.3554, -0.1230,  ..., -0.4464,  0.2186,  0.2299],\n",
       "          [-0.0439, -0.2538,  0.2240,  ..., -0.3289,  0.2388,  0.0936],\n",
       "          ...,\n",
       "          [-0.0227, -0.0283, -0.0234,  ..., -0.0248,  0.0264,  0.0290],\n",
       "          [-0.0157, -0.0147, -0.0199,  ..., -0.0183,  0.0176,  0.0172],\n",
       "          [-0.0095, -0.0189, -0.0128,  ..., -0.0086,  0.0077,  0.0234]],\n",
       "         device='cuda:0', requires_grad=True)),\n",
       " ('v_embeddings.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.3588,  0.3797,  0.4175,  ...,  0.3737, -0.3812, -0.4007],\n",
       "          [ 0.3953,  0.3887,  0.4004,  ...,  0.3583, -0.3541, -0.4233],\n",
       "          [ 0.4475,  0.4058,  0.3744,  ...,  0.3832, -0.4502, -0.3947]],\n",
       "         device='cuda:0', requires_grad=True))]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(skip_gram_model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((skip_gram_model.v_embeddings.weight.abs()>1e-16).detach().cpu() == mask).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        ...,\n",
       "        [ True,  True,  True,  ...,  True,  True,  True],\n",
       "        [ True,  True,  True,  ...,  True,  True,  True],\n",
       "        [ True,  True,  True,  ...,  True,  True,  True]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_gram_model.v_embeddings.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_VISIBLE_DEVICES=6 python main.py --pruned True --prune_amount 0.1 --valid data/valid.txt --save_dir exp1 --save_file sgns_oneshot_0.1  &\n",
      "CUDA_VISIBLE_DEVICES=6 python main.py --pruned True --prune_amount 0.2 --valid data/valid.txt --save_dir exp1 --save_file sgns_oneshot_0.2  &\n",
      "CUDA_VISIBLE_DEVICES=6 python main.py --pruned True --prune_amount 0.3 --valid data/valid.txt --save_dir exp1 --save_file sgns_oneshot_0.3  &\n",
      "CUDA_VISIBLE_DEVICES=6 python main.py --pruned True --prune_amount 0.4 --valid data/valid.txt --save_dir exp1 --save_file sgns_oneshot_0.4  &\n",
      "CUDA_VISIBLE_DEVICES=6 python main.py --pruned True --prune_amount 0.5 --valid data/valid.txt --save_dir exp1 --save_file sgns_oneshot_0.5  &\n",
      "CUDA_VISIBLE_DEVICES=6 python main.py --pruned True --prune_amount 0.6 --valid data/valid.txt --save_dir exp1 --save_file sgns_oneshot_0.6  &\n",
      "CUDA_VISIBLE_DEVICES=6 python main.py --pruned True --prune_amount 0.7 --valid data/valid.txt --save_dir exp1 --save_file sgns_oneshot_0.7  &\n",
      "CUDA_VISIBLE_DEVICES=6 python main.py --pruned True --prune_amount 0.8 --valid data/valid.txt --save_dir exp1 --save_file sgns_oneshot_0.8  &\n",
      "CUDA_VISIBLE_DEVICES=6 python main.py --pruned True --prune_amount 0.9 --valid data/valid.txt --save_dir exp1 --save_file sgns_oneshot_0.9  &\n",
      "CUDA_VISIBLE_DEVICES=6 python main.py --pruned True --prune_amount 0.95 --valid data/valid.txt --save_dir exp1 --save_file sgns_oneshot_0.95  &\n",
      "CUDA_VISIBLE_DEVICES=6 python main.py --pruned True --prune_amount 0.99 --valid data/valid.txt --save_dir exp1 --save_file sgns_oneshot_0.99  &\n"
     ]
    }
   ],
   "source": [
    "command = 'CUDA_VISIBLE_DEVICES=6 python main.py --pruned True --prune_amount {0} --valid data/valid.txt --save_dir exp1 --save_file sgns_oneshot_{0}'\n",
    "for prune_rate in [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.95,0.99]:\n",
    "    print(command.format(prune_rate), end='  &\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
