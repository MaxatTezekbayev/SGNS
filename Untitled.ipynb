{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('u_embeddings.weight',\n",
       "              tensor([[-0.0004, -0.0041,  0.0032,  ..., -0.0041,  0.0003,  0.0006],\n",
       "                      [ 0.0043,  0.0017,  0.0047,  ...,  0.0018, -0.0041,  0.0033],\n",
       "                      [-0.0021,  0.0017, -0.0031,  ...,  0.0048, -0.0042, -0.0044],\n",
       "                      ...,\n",
       "                      [ 0.0016, -0.0039,  0.0009,  ..., -0.0004,  0.0020,  0.0046],\n",
       "                      [ 0.0036,  0.0047, -0.0005,  ...,  0.0010, -0.0016, -0.0022],\n",
       "                      [ 0.0003, -0.0004, -0.0030,  ..., -0.0032,  0.0032,  0.0031]])),\n",
       "             ('v_embeddings.weight',\n",
       "              tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      ...,\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.]]))])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "init = torch.load('initial_state_dict_sgns.pth')\n",
    "init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('u_embeddings.weight',\n",
       "              tensor([[ 0.0012, -0.1110, -0.0614,  ..., -0.0707,  0.0100,  0.0796],\n",
       "                      [ 0.0316, -0.0280, -0.0487,  ..., -0.0661, -0.0004, -0.0005],\n",
       "                      [ 0.0323, -0.0611,  0.0128,  ...,  0.0134, -0.0244,  0.0239],\n",
       "                      ...,\n",
       "                      [ 0.0280, -0.0300, -0.0254,  ..., -0.0263,  0.0276,  0.0305],\n",
       "                      [ 0.0230, -0.0147, -0.0199,  ..., -0.0184,  0.0178,  0.0172],\n",
       "                      [ 0.0181, -0.0180, -0.0208,  ..., -0.0206,  0.0207,  0.0207]],\n",
       "                     device='cuda:0')),\n",
       "             ('v_embeddings.weight',\n",
       "              tensor([[-0.3988,  0.1705,  0.2404,  ...,  0.1758, -0.3485, -0.2241],\n",
       "                      [-0.1896,  0.1612,  0.1672,  ...,  0.1032, -0.2210, -0.2103],\n",
       "                      [-0.0178,  0.0582,  0.2122,  ...,  0.0733, -0.1144, -0.1156],\n",
       "                      ...,\n",
       "                      [-0.8320,  0.8458,  0.8173,  ...,  0.7397, -0.7814, -0.8113],\n",
       "                      [-0.8533,  0.8619,  0.8167,  ...,  0.7722, -0.7554, -0.8360],\n",
       "                      [-0.7837,  0.8141,  0.8239,  ...,  0.7547, -0.7019, -0.8132]],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = torch.load('final_state_dict_sgns.pth')\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data .................\n",
      "Total tokens: 17005207\n",
      "Vocabulary size: 71290\n"
     ]
    }
   ],
   "source": [
    "import data\n",
    "import model\n",
    "\n",
    "argsdata='data/text8'\n",
    "argsemsize = 200\n",
    "argsbatch_size = 1024\n",
    "argswindow_size=5\n",
    "argsneg_num=5\n",
    "argsmin_count=5\n",
    "\n",
    "\n",
    "\n",
    "my_data = data.DataReader(argsdata, argsmin_count)\n",
    "dataset = data.Word2vecDataset(my_data, argswindow_size, argsneg_num)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "  dataset, batch_size=argsbatch_size, collate_fn=dataset.collate)\n",
    "\n",
    "\n",
    "vocab_size = len(my_data.word2id)\n",
    "skip_gram_model = model.SkipGramModel(vocab_size, argsemsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
